{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XvW2FYFhDVet"
      },
      "source": [
        "<a href=\"http://cocl.us/pytorch_link_top\">\n",
        "    <img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0110EN/notebook_images%20/Pytochtop.png\" width=\"750\" alt=\"IBM Product \">\n",
        "</a>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QEQ_aM9XDVev"
      },
      "source": [
        "<img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DL0321EN-SkillsNetwork/image/IDSN-logo.png\" width=\"200\" alt=\"cognitiveclass.ai logo\">\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfgPyUocDVew"
      },
      "source": [
        "<h1><h1>Pre-trained-Models with PyTorch </h1>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HN3p-hDCDVew"
      },
      "source": [
        "In this lab, you will use pre-trained models to classify between the negative and positive samples; you will be provided with the dataset object. The particular pre-trained model will be resnet18; you will have three questions:\n",
        "<ul>\n",
        "<li>change the output layer</li>\n",
        "<li> train the model</li>\n",
        "<li>  identify  several  misclassified samples</li>\n",
        " </ul>\n",
        "You will take several screenshots of your work and share your notebook.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3DouWqzDVex"
      },
      "source": [
        "<h2>Table of Contents</h2>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-91ihwM7DVex"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n",
        "\n",
        "\n",
        "<ul>\n",
        "    <li><a href=\"#download_data\"> Download Data</a></li>\n",
        "    <li><a href=\"#auxiliary\"> Imports and Auxiliary Functions </a></li>\n",
        "    <li><a href=\"#data_class\"> Dataset Class</a></li>\n",
        "    <li><a href=\"#Question_1\">Question 1</a></li>\n",
        "    <li><a href=\"#Question_2\">Question 2</a></li>\n",
        "    <li><a href=\"#Question_3\">Question 3</a></li>\n",
        "</ul>\n",
        "<p>Estimated Time Needed: <strong>120 min</strong></p>\n",
        " </div>\n",
        "<hr>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zM2a2j9GDVey"
      },
      "source": [
        "<h2 id=\"download_data\">Download Data</h2>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Em3Imd5TDVey"
      },
      "source": [
        "Download the dataset and unzip the files in your data directory, unlike the other labs, all the data will be deleted after you close  the lab, this may take some time:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "INcyJ2NKDVez",
        "outputId": "04bb02b2-26a9-4a77-dbaf-7a9ed8d77083"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-09-01 04:09:12--  https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0321EN/data/images/Positive_tensors.zip\n",
            "Resolving s3-api.us-geo.objectstorage.softlayer.net (s3-api.us-geo.objectstorage.softlayer.net)... 67.228.254.196\n",
            "Connecting to s3-api.us-geo.objectstorage.softlayer.net (s3-api.us-geo.objectstorage.softlayer.net)|67.228.254.196|:443... connected.\n",
            "HTTP request sent, awaiting response... 304 Not Modified\n",
            "File ‘Positive_tensors.zip’ not modified on server. Omitting download.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget -N https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0321EN/data/images/Positive_tensors.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "tags": [],
        "id": "a6TcQrw7DVe0"
      },
      "outputs": [],
      "source": [
        "!unzip -oq Positive_tensors.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IvHV7Dv4DVe1",
        "outputId": "a47b21b9-cb68-458b-c72b-dced4abc2ab9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-09-01 04:13:07--  https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0321EN/data/images/Negative_tensors.zip\n",
            "Resolving s3-api.us-geo.objectstorage.softlayer.net (s3-api.us-geo.objectstorage.softlayer.net)... 67.228.254.196\n",
            "Connecting to s3-api.us-geo.objectstorage.softlayer.net (s3-api.us-geo.objectstorage.softlayer.net)|67.228.254.196|:443... connected.\n",
            "HTTP request sent, awaiting response... 304 Not Modified\n",
            "File ‘Negative_tensors.zip’ not modified on server. Omitting download.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "! wget -N https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0321EN/data/images/Negative_tensors.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -oq Negative_tensors.zip"
      ],
      "metadata": {
        "id": "lIqvRCLdxZPY"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CItlzqh0DVe1"
      },
      "source": [
        "We will install torchvision:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lhb4Sd2DDVe1",
        "outputId": "1b67b5a3-774b-4b4c-8dd3-7e7d9c047f64"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.19.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: torch==2.4.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.4.0+cu121)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchvision) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchvision) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchvision) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchvision) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchvision) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchvision) (2024.6.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.4.0->torchvision) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.4.0->torchvision) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torchvision"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VzCxNRiFDVe2"
      },
      "source": [
        "<h2 id=\"auxiliary\">Imports and Auxiliary Functions</h2>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gr2HVGoHDVe2"
      },
      "source": [
        "The following are the libraries we are going to use for this lab. The <code>torch.manual_seed()</code> is for forcing the random function to give the same number every time we try to recompile it.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3B26z4sODVe2",
        "outputId": "f43ae6d1-bf83-4268-c293-9f3b24997b3f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fa6f8262390>"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ],
      "source": [
        "# These are the libraries will be used for this lab.\n",
        "import torchvision.models as models\n",
        "from PIL import Image\n",
        "import pandas\n",
        "from torchvision import transforms\n",
        "import torch.nn as nn\n",
        "import time\n",
        "import torch\n",
        "import matplotlib.pylab as plt\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import h5py\n",
        "import os\n",
        "import glob\n",
        "torch.manual_seed(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "tags": [],
        "id": "meWycTxJDVe3"
      },
      "outputs": [],
      "source": [
        "from matplotlib.pyplot import imshow\n",
        "import matplotlib.pylab as plt\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bLNZusxXDVe3"
      },
      "source": [
        "<!--Empty Space for separating topics-->\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rViFkxqvDVe3"
      },
      "source": [
        "<h2 id=\"data_class\">Dataset Class</h2>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ZxfSV4lDVe3"
      },
      "source": [
        " This dataset class is essentially the same dataset you build in the previous section, but to speed things up, we are going to use tensors instead of jpeg images. Therefor for each iteration, you will skip the reshape step, conversion step to tensors and normalization step.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LySj2uJCDVe3",
        "outputId": "f003de5c-ea49-43de-eb6f-2a6bfdd61cc0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "done\n"
          ]
        }
      ],
      "source": [
        "# Create your own dataset object\n",
        "\n",
        "class Dataset(Dataset):\n",
        "\n",
        "    # Constructor\n",
        "    def __init__(self,transform=None,train=True):\n",
        "        # directory=\"/home/wsuser/work\"\n",
        "        directory = '.'\n",
        "        positive=\"Positive_tensors\"\n",
        "        negative='Negative_tensors'\n",
        "\n",
        "        positive_file_path=os.path.join(directory,positive)\n",
        "        negative_file_path=os.path.join(directory,negative)\n",
        "        positive_files=[os.path.join(positive_file_path,file) for file in os.listdir(positive_file_path) if file.endswith(\".pt\")]\n",
        "        negative_files=[os.path.join(negative_file_path,file) for file in os.listdir(negative_file_path) if file.endswith(\".pt\")]\n",
        "        number_of_samples=len(positive_files)+len(negative_files)\n",
        "        self.all_files=[None]*number_of_samples\n",
        "        self.all_files[::2]=positive_files\n",
        "        self.all_files[1::2]=negative_files\n",
        "        # The transform is goint to be used on image\n",
        "        self.transform = transform\n",
        "        #torch.LongTensor\n",
        "        self.Y=torch.zeros([number_of_samples]).type(torch.LongTensor).to(device)\n",
        "        self.Y[::2]=1\n",
        "        self.Y[1::2]=0\n",
        "        self.Y = self.Y.to(device)\n",
        "\n",
        "        if train:\n",
        "            self.all_files=self.all_files[0:30000]\n",
        "            self.Y=self.Y[0:30000]\n",
        "            self.len=len(self.all_files)\n",
        "        else:\n",
        "            self.all_files=self.all_files[30000:]\n",
        "            self.Y=self.Y[30000:]\n",
        "            self.len=len(self.all_files)\n",
        "\n",
        "    # Get the length\n",
        "    def __len__(self):\n",
        "        return self.len\n",
        "\n",
        "    # Getter\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        image=torch.load(self.all_files[idx])\n",
        "        y=self.Y[idx]\n",
        "\n",
        "        # If there is any transform method, apply it onto the image\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, y\n",
        "\n",
        "print(\"done\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4VJOI6rUDVe3"
      },
      "source": [
        "We create two dataset objects, one for the training data and one for the validation data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G8Tkf6VYDVe3",
        "outputId": "de6a3f86-5762-4b15-e561-beed602e4804"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "done\n"
          ]
        }
      ],
      "source": [
        "mean = [0.485, 0.456, 0.406]\n",
        "std = [0.229, 0.224, 0.225]\n",
        "\n",
        "composed = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.Resize(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean, std)\n",
        "])\n",
        "\n",
        "train_dataset = Dataset(train=True, transform=composed)\n",
        "validation_dataset = Dataset(train=False, transform=composed)\n",
        "print(\"done\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "cuda_id = torch.cuda.current_device()\n",
        "device_name = torch.cuda.get_device_name(cuda_id)\n",
        "cuda_id, device_name, device"
      ],
      "metadata": {
        "id": "athsYx7BUPjL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28c70f26-e23d-42a0-9011-79b19b5f0688"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0, 'Tesla T4', 'cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sl0tI8xNDVe4"
      },
      "source": [
        "<h2 id=\"Question_1\">Question 1</h2>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HNcqbTtqDVe4"
      },
      "source": [
        "<b>Prepare a pre-trained resnet18 model :</b>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PfAYvhZHDVe4"
      },
      "source": [
        "<b>Step 1</b>: Load the pre-trained model <code>resnet18</code> Set the parameter <code>pretrained</code> to true:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "tags": [],
        "id": "_iMzLHk-DVe4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3587f3b0-7fa0-4a4a-f74f-418c5e3ea4fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Load the pre-trained model resnet18\n",
        "\n",
        "# Type your code here\n",
        "model = models.resnet18(pretrained=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5vIbTOXeDVe4"
      },
      "source": [
        "<b>Step 2</b>: Set the attribute <code>requires_grad</code> to <code>False</code>. As a result, the parameters will not be affected by training.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "tags": [],
        "id": "vSuitQBADVe5"
      },
      "outputs": [],
      "source": [
        "# Step 2: Set the parameter cannot be trained for the pre-trained model\n",
        "\n",
        "# Type your code here\n",
        "for param in model.parameters():\n",
        "    param.require_grad = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OhvWuna3DVe5"
      },
      "source": [
        "<code>resnet18</code> is used to classify 1000 different objects; as a result, the last layer has 1000 outputs.  The 512 inputs come from the fact that the previously hidden layer has 512 outputs.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Adv0mEjiDVe5"
      },
      "source": [
        "<b>Step 3</b>: Replace the output layer <code>model.fc</code> of the neural network with a <code>nn.Linear</code> object, to classify 2 different classes. For the parameters <code>in_features </code> remember the last hidden layer has 512 neurons.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "tags": [],
        "id": "t1KdiV-7DVe5"
      },
      "outputs": [],
      "source": [
        "model.fc = nn.Linear(512, 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TrZNylmcDVe5"
      },
      "source": [
        "Print out the model in order to show whether you get the correct answer.<br> <b>(Your peer reviewer is going to mark based on what you print here.)</b>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "tags": [],
        "id": "EwCph2AGDVe6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f65b450d-ec51-4525-a9c9-cf109d898f6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Linear(in_features=512, out_features=2, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V7iGWX_ZDVe6"
      },
      "source": [
        "<h2 id=\"Question_2\">Question 2: Train the Model</h2>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UB7wlARgDVe6"
      },
      "source": [
        "In this question you will train your, model:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hN3K3dUcDVe6"
      },
      "source": [
        "<b>Step 1</b>: Create a cross entropy criterion function\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "3eOevx4dDVe7"
      },
      "outputs": [],
      "source": [
        "# Step 1: Create the loss function\n",
        "\n",
        "# Type your code here\n",
        "criterion = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6r1KwghpDVe7"
      },
      "source": [
        "<b>Step 2</b>: Create a training loader and validation loader object, the batch size should have 100 samples each.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "tags": [],
        "id": "Ra2JS8SGDVe7"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "batch_size = 100\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size)\n",
        "val_loader = torch.utils.data.DataLoader(dataset=validation_dataset, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "79rE3e5iDVe8"
      },
      "source": [
        "<b>Step 3</b>: Use the following optimizer to minimize the loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "tags": [],
        "id": "Icg5qxYJDVe8"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.Adam([parameters  for parameters in model.parameters() if parameters.requires_grad],lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Optimize for speed when e have GPU\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "uiQstUmLVUk5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9bc1db39-51cb-4f8d-92bd-878ca6bc918c"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=512, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KBSmL900DVe8"
      },
      "source": [
        "<!--Empty Space for separating topics-->\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SeqAqvnHDVe8"
      },
      "source": [
        "**Complete the following code to calculate  the accuracy on the validation data for one epoch; this should take about 45 minutes. Make sure you calculate the accuracy on the validation data.**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mMMNu9j2DVe8",
        "outputId": "e22467e9-ee7b-47ac-87d7-53aeafcf6da1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-92-a5b193e0f98a>:44: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  image=torch.load(self.all_files[idx])\n"
          ]
        }
      ],
      "source": [
        "n_epochs=1\n",
        "loss_list=[]\n",
        "accuracy_list=[]\n",
        "correct=0\n",
        "N_test=len(validation_dataset)\n",
        "N_train=len(train_dataset)\n",
        "start_time = time.time()\n",
        "#n_epochs\n",
        "\n",
        "Loss=0\n",
        "start_time = time.time()\n",
        "for epoch in range(n_epochs):\n",
        "    for x, y in train_loader:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        model.train()\n",
        "        #clear gradient\n",
        "        optimizer.zero_grad()\n",
        "        #make a prediction\n",
        "        yhat = model(x)\n",
        "        # calculate loss\n",
        "        loss = criterion(yhat, y)\n",
        "        # calculate gradients of parameters\n",
        "        loss.backward()\n",
        "        # update parameters\n",
        "        optimizer.step()\n",
        "\n",
        "        loss_list.append(loss.data)\n",
        "    correct=0\n",
        "    for x_test, y_test in val_loader:\n",
        "        # set model to eval\n",
        "        x_test, y_test = x_test.to(device), y_test.to(device)\n",
        "        model.eval()\n",
        "        #make a prediction\n",
        "        yhat = model(x_test)\n",
        "        #find max\n",
        "        _, yhat = torch.max(yhat.data, 1)\n",
        "\n",
        "        #Calculate misclassified  samples in mini-batch\n",
        "        #hint +=(yhat==y_test).sum().item()\n",
        "        correct += (yhat == y_test).sum().item()\n",
        "\n",
        "    accuracy = correct / N_test\n",
        "    accuracy_list.append(accuracy)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3FdLRLJDVe9"
      },
      "source": [
        "<b>Print out the Accuracy and plot the loss stored in the list <code>loss_list</code> for every iteration and take a screen shot.</b>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "tags": [],
        "id": "yrumB-ZRDVe9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a455c867-26b8-460e-9e9e-35ce7b6ce1ba"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9952"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ],
      "source": [
        "accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "tags": [],
        "id": "P2F1cb60DVe9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "outputId": "5b64d6ed-7961-410c-a4a6-66e08e0fb1c4"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "loss_list = loss_list if device == 'cpu' else [loss.cpu() for loss in loss_list]\n",
        "plt.plot(loss_list)\n",
        "plt.xlabel(\"iteration\")\n",
        "plt.ylabel(\"loss\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J4P62jKpDVe-"
      },
      "source": [
        "<h2 id=\"Question_3\">Question 3:Find the misclassified samples</h2>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bL-C6WpODVe-"
      },
      "source": [
        "<b>Identify the first four misclassified samples using the validation data:</b>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "id": "EETZvh9ZDVe-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ced348eb-10ab-4265-ccb4-6be6b5e9862a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-92-a5b193e0f98a>:44: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  image=torch.load(self.all_files[idx])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample 503 yhat: tensor([1], device='cuda:0') y:tensor([0], device='cuda:0')\n",
            "sample 659 yhat: tensor([1], device='cuda:0') y:tensor([0], device='cuda:0')\n",
            "sample 1021 yhat: tensor([1], device='cuda:0') y:tensor([0], device='cuda:0')\n",
            "sample 1100 yhat: tensor([0], device='cuda:0') y:tensor([1], device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "validation_loader = torch.utils.data.DataLoader(dataset=validation_dataset, batch_size=1)\n",
        "\n",
        "# Plot the misclassified samples\n",
        "count = 0\n",
        "model.eval()\n",
        "for idx, (x_test, y_test) in enumerate(validation_loader):\n",
        "    x_test, y_test = x_test.to(device), y_test.to(device)\n",
        "    z = model(x_test.reshape(-1,3,224,224))\n",
        "    _,yhat = torch.max(z.data, 1)\n",
        "    if yhat != y_test:\n",
        "        print(\"sample {} yhat: {} y:{}\".format(idx, yhat, y_test))\n",
        "        count += 1\n",
        "    if count >= 4:\n",
        "        break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nImUqzK1DVe-"
      },
      "source": [
        "<a href=\"https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/share-notebooks.html?utm_source=Exinfluencer&utm_content=000026UJ&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkDL0321ENSkillsNetwork951-2022-01-01&utm_medium=Exinfluencer&utm_term=10006555\"> CLICK HERE </a> Click here to see how to share your notebook.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XPxqSAR8DVe-"
      },
      "source": [
        "<h2>About the Authors:</h2>\n",
        "\n",
        "<a href=\"https://www.linkedin.com/in/joseph-s-50398b136/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkDL0321ENSkillsNetwork951-2022-01-01\">Joseph Santarcangelo</a> has a PhD in Electrical Engineering, his research focused on using machine learning, signal processing, and computer vision to determine how videos impact human cognition. Joseph has been working for IBM since he completed his PhD.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8PPpw8JjDVe_"
      },
      "source": [
        "\n",
        "## Change Log\n",
        "\n",
        "|  Date (YYYY-MM-DD) |  Version | Changed By  |  Change Description |\n",
        "|---|---|---|---|\n",
        "| 2020-09-21  | 2.0  | Shubham  |  Migrated Lab to Markdown and added to course repo in GitLab |\n",
        "\n",
        "\n",
        "\n",
        "<hr>\n",
        "\n",
        "## <h3 align=\"center\"> © IBM Corporation 2020. All rights reserved. <h3/>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5FAkWpbDVe_"
      },
      "source": [
        "Copyright &copy; 2018 <a href=\"cognitiveclass.ai?utm_source=bducopyrightlink&utm_medium=dswb&utm_campaign=bdu\">cognitiveclass.ai</a>. This notebook and its source code are released under the terms of the <a href=\"https://bigdatauniversity.com/mit-license/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkDL0321ENSkillsNetwork951-2022-01-01\">MIT License</a>.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}