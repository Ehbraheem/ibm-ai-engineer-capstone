{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"http://cocl.us/pytorch_link_top\">\n",
    "    <img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0110EN/notebook_images%20/Pytochtop.png\" width=\"750\" alt=\"IBM Product \">\n",
    "</a> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DL0321EN-SkillsNetwork/image/IDSN-logo.png\" width=\"200\" alt=\"cognitiveclass.ai logo\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Objective</h1><ul><li> How to use linear classifier in pytorch.</li></ul> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Linear  Classifier with PyTorch </h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Before you use a  Deep neural network to solve the classification problem,  it 's a good idea to try and solve the problem with the simplest method. You will need the dataset object from the previous section.\n",
    "In this lab, we solve the problem with a linear classifier.\n",
    " You will be asked to determine the maximum accuracy your linear classifier can achieve on the validation data for 5 epochs. We will give some free parameter values if you follow the instructions you will be able to answer the quiz. Just like the other labs there are several steps, but in this lab you will only be quizzed on the final result. </p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Table of Contents</h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n",
    "\n",
    "\n",
    "<ul>\n",
    "    <li><a href=\"#auxiliary\"> Imports and Auxiliary Functions </a></li>\n",
    "    <li><a href=\"#download_data\"> Download data</a></li>\n",
    "    <li><a href=\"#data_class\"> Dataset Class</a></li>\n",
    "    <li><a href=\"#trasform_Data_object\">Transform Object and Dataset Object</a></li>\n",
    "    <li><a href=\"#Question\">Question</a></li>\n",
    "</ul>\n",
    "<p>Estimated Time Needed: <strong>25 min</strong></p>\n",
    " </div>\n",
    "<hr>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"auxiliary\">Imports and Auxiliary Functions</h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following are the libraries we are going to use for this lab:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: skillsnetwork in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (0.20.6)\n",
      "Requirement already satisfied: ipython in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from skillsnetwork) (7.33.0)\n",
      "Requirement already satisfied: ipywidgets<8,>=7 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from skillsnetwork) (7.4.2)\n",
      "Requirement already satisfied: requests<3,>=2 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from skillsnetwork) (2.29.0)\n",
      "Requirement already satisfied: tqdm<5,>=4 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from skillsnetwork) (4.60.0)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from ipywidgets<8,>=7->skillsnetwork) (6.16.2)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from ipywidgets<8,>=7->skillsnetwork) (5.9.0)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from ipywidgets<8,>=7->skillsnetwork) (5.8.0)\n",
      "Requirement already satisfied: widgetsnbextension~=3.4.0 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from ipywidgets<8,>=7->skillsnetwork) (3.4.2)\n",
      "Requirement already satisfied: setuptools>=18.5 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from ipython->skillsnetwork) (67.7.2)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from ipython->skillsnetwork) (0.18.2)\n",
      "Requirement already satisfied: decorator in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from ipython->skillsnetwork) (5.1.1)\n",
      "Requirement already satisfied: pickleshare in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from ipython->skillsnetwork) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from ipython->skillsnetwork) (3.0.38)\n",
      "Requirement already satisfied: pygments in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from ipython->skillsnetwork) (2.15.1)\n",
      "Requirement already satisfied: backcall in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from ipython->skillsnetwork) (0.2.0)\n",
      "Requirement already satisfied: matplotlib-inline in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from ipython->skillsnetwork) (0.1.6)\n",
      "Requirement already satisfied: pexpect>4.3 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from ipython->skillsnetwork) (4.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from requests<3,>=2->skillsnetwork) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from requests<3,>=2->skillsnetwork) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from requests<3,>=2->skillsnetwork) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from requests<3,>=2->skillsnetwork) (2023.5.7)\n",
      "Requirement already satisfied: debugpy>=1.0 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from ipykernel>=4.5.1->ipywidgets<8,>=7->skillsnetwork) (1.6.3)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from ipykernel>=4.5.1->ipywidgets<8,>=7->skillsnetwork) (7.4.9)\n",
      "Requirement already satisfied: nest-asyncio in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from ipykernel>=4.5.1->ipywidgets<8,>=7->skillsnetwork) (1.5.6)\n",
      "Requirement already satisfied: packaging in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from ipykernel>=4.5.1->ipywidgets<8,>=7->skillsnetwork) (23.1)\n",
      "Requirement already satisfied: psutil in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from ipykernel>=4.5.1->ipywidgets<8,>=7->skillsnetwork) (5.9.3)\n",
      "Requirement already satisfied: pyzmq>=17 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from ipykernel>=4.5.1->ipywidgets<8,>=7->skillsnetwork) (24.0.1)\n",
      "Requirement already satisfied: tornado>=6.1 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from ipykernel>=4.5.1->ipywidgets<8,>=7->skillsnetwork) (6.2)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from jedi>=0.16->ipython->skillsnetwork) (0.8.3)\n",
      "Requirement already satisfied: fastjsonschema in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from nbformat>=4.2.0->ipywidgets<8,>=7->skillsnetwork) (2.16.3)\n",
      "Requirement already satisfied: importlib-metadata>=3.6 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from nbformat>=4.2.0->ipywidgets<8,>=7->skillsnetwork) (4.11.4)\n",
      "Requirement already satisfied: jsonschema>=2.6 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from nbformat>=4.2.0->ipywidgets<8,>=7->skillsnetwork) (4.17.3)\n",
      "Requirement already satisfied: jupyter-core in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from nbformat>=4.2.0->ipywidgets<8,>=7->skillsnetwork) (4.12.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from pexpect>4.3->ipython->skillsnetwork) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->skillsnetwork) (0.2.6)\n",
      "Requirement already satisfied: notebook>=4.4.1 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from widgetsnbextension~=3.4.0->ipywidgets<8,>=7->skillsnetwork) (6.5.4)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from importlib-metadata>=3.6->nbformat>=4.2.0->ipywidgets<8,>=7->skillsnetwork) (3.15.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from importlib-metadata>=3.6->nbformat>=4.2.0->ipywidgets<8,>=7->skillsnetwork) (4.5.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from jsonschema>=2.6->nbformat>=4.2.0->ipywidgets<8,>=7->skillsnetwork) (23.1.0)\n",
      "Requirement already satisfied: importlib-resources>=1.4.0 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from jsonschema>=2.6->nbformat>=4.2.0->ipywidgets<8,>=7->skillsnetwork) (5.12.0)\n",
      "Requirement already satisfied: pkgutil-resolve-name>=1.3.10 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from jsonschema>=2.6->nbformat>=4.2.0->ipywidgets<8,>=7->skillsnetwork) (1.3.10)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from jsonschema>=2.6->nbformat>=4.2.0->ipywidgets<8,>=7->skillsnetwork) (0.19.3)\n",
      "Requirement already satisfied: entrypoints in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets<8,>=7->skillsnetwork) (0.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets<8,>=7->skillsnetwork) (2.8.2)\n",
      "Requirement already satisfied: jinja2 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.4.0->ipywidgets<8,>=7->skillsnetwork) (3.1.2)\n",
      "Requirement already satisfied: argon2-cffi in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.4.0->ipywidgets<8,>=7->skillsnetwork) (21.3.0)\n",
      "Requirement already satisfied: ipython-genutils in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.4.0->ipywidgets<8,>=7->skillsnetwork) (0.2.0)\n",
      "Requirement already satisfied: nbconvert>=5 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.4.0->ipywidgets<8,>=7->skillsnetwork) (7.4.0)\n",
      "Requirement already satisfied: Send2Trash>=1.8.0 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.4.0->ipywidgets<8,>=7->skillsnetwork) (1.8.2)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.4.0->ipywidgets<8,>=7->skillsnetwork) (0.17.1)\n",
      "Requirement already satisfied: prometheus-client in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.4.0->ipywidgets<8,>=7->skillsnetwork) (0.16.0)\n",
      "Requirement already satisfied: nbclassic>=0.4.7 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.4.0->ipywidgets<8,>=7->skillsnetwork) (1.0.0)\n",
      "Requirement already satisfied: jupyter-server>=1.8 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.4.0->ipywidgets<8,>=7->skillsnetwork) (1.24.0)\n",
      "Requirement already satisfied: notebook-shim>=0.2.3 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.4.0->ipywidgets<8,>=7->skillsnetwork) (0.2.3)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.4.0->ipywidgets<8,>=7->skillsnetwork) (4.11.1)\n",
      "Requirement already satisfied: bleach in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.4.0->ipywidgets<8,>=7->skillsnetwork) (6.0.0)\n",
      "Requirement already satisfied: defusedxml in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.4.0->ipywidgets<8,>=7->skillsnetwork) (0.7.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.4.0->ipywidgets<8,>=7->skillsnetwork) (0.2.2)\n",
      "Requirement already satisfied: markupsafe>=2.0 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.4.0->ipywidgets<8,>=7->skillsnetwork) (2.1.1)\n",
      "Requirement already satisfied: mistune<3,>=2.0.3 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.4.0->ipywidgets<8,>=7->skillsnetwork) (2.0.5)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.4.0->ipywidgets<8,>=7->skillsnetwork) (0.7.4)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.4.0->ipywidgets<8,>=7->skillsnetwork) (1.5.0)\n",
      "Requirement already satisfied: tinycss2 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.4.0->ipywidgets<8,>=7->skillsnetwork) (1.2.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from python-dateutil>=2.8.2->jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets<8,>=7->skillsnetwork) (1.16.0)\n",
      "Requirement already satisfied: argon2-cffi-bindings in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.4.0->ipywidgets<8,>=7->skillsnetwork) (21.2.0)\n",
      "Requirement already satisfied: anyio<4,>=3.1.0 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.4.0->ipywidgets<8,>=7->skillsnetwork) (3.6.2)\n",
      "Requirement already satisfied: websocket-client in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.4.0->ipywidgets<8,>=7->skillsnetwork) (1.5.1)\n",
      "Requirement already satisfied: cffi>=1.0.1 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.4.0->ipywidgets<8,>=7->skillsnetwork) (1.15.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.4.0->ipywidgets<8,>=7->skillsnetwork) (2.3.2.post1)\n",
      "Requirement already satisfied: webencodings in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from bleach->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.4.0->ipywidgets<8,>=7->skillsnetwork) (0.5.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from anyio<4,>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.4.0->ipywidgets<8,>=7->skillsnetwork) (1.3.0)\n",
      "Requirement already satisfied: pycparser in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.4.0->ipywidgets<8,>=7->skillsnetwork) (2.21)\n"
     ]
    }
   ],
   "source": [
    "!pip install skillsnetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "from torch import optim \n",
    "import skillsnetwork "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"download_data\">Download Data</h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, you are going to download the data from IBM object storage using **skillsnetwork.prepare** command. <b>skillsnetwork.prepare</b> is a command that's used to download a zip file, unzip it and store it in a specified directory. Locally we store the data in the directory  **/resources/data**. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we download the file that contains the images:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir -p ./resources/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ca853316ac4466bb9fef87a57d1b68c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading concrete_crack_images_for_classification.zip:   0%|          | 0/245259777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "353093ba04364bc0a3660654e424ead8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to 'resources/data'\n"
     ]
    }
   ],
   "source": [
    "await skillsnetwork.prepare(\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0321EN/data/images/concrete_crack_images_for_classification.zip\", path = \"./resources/data\", overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"data_class\">Dataset Class</h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will use the previous code to build a dataset class. As before, make sure the even samples are positive, and the odd samples are negative.  In this case, if the parameter <code>train</code> is set to <code>True</code>, use the first 10 000 samples as training data; otherwise, the last 10 000 samples will be used as validation data. Do not forget to sort your files so they are in the same order.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** We are using the first 10,000 samples as our training data instead of the available 30,000 to decrease the training time of the model. If you want, you can train it yourself with all 30,000 samples just by modifying 2 lines in the following code chunk.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Dataset(Dataset):\n",
    "\n",
    "    # Constructor\n",
    "    def __init__(self,transform=None,train=True):\n",
    "        directory=\"./resources/data\"\n",
    "        positive=\"Positive\"\n",
    "        negative=\"Negative\"\n",
    "\n",
    "        positive_file_path=os.path.join(directory,positive)\n",
    "        negative_file_path=os.path.join(directory,negative)\n",
    "        positive_files=[os.path.join(positive_file_path,file) for file in  os.listdir(positive_file_path) if file.endswith(\".jpg\")]\n",
    "        positive_files.sort()\n",
    "        negative_files=[os.path.join(negative_file_path,file) for file in  os.listdir(negative_file_path) if file.endswith(\".jpg\")]\n",
    "        negative_files.sort()\n",
    "        number_of_samples=len(positive_files)+len(negative_files)\n",
    "        self.all_files=[None]*number_of_samples\n",
    "        self.all_files[::2]=positive_files\n",
    "        self.all_files[1::2]=negative_files \n",
    "        # The transform is goint to be used on image\n",
    "        self.transform = transform\n",
    "        #torch.LongTensor\n",
    "        self.Y=torch.zeros([number_of_samples]).type(torch.LongTensor)\n",
    "        self.Y[::2]=1\n",
    "        self.Y[1::2]=0\n",
    "        \n",
    "        if train:\n",
    "            self.all_files=self.all_files[0:10000] #Change to 30000 to use the full test dataset\n",
    "            self.Y=self.Y[0:10000] #Change to 30000 to use the full test dataset\n",
    "            self.len=len(self.all_files)\n",
    "        else:\n",
    "            self.all_files=self.all_files[30000:]\n",
    "            self.Y=self.Y[30000:]\n",
    "            self.len=len(self.all_files)    \n",
    "       \n",
    "    # Get the length\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "    # Getter\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        \n",
    "        image=Image.open(self.all_files[idx])\n",
    "        y=self.Y[idx]\n",
    "          \n",
    "        \n",
    "        # If there is any transform method, apply it onto the image\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"trasform_Data_object\">Transform Object and Dataset Object</h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a transform object, that uses the <code>Compose</code> function. First use the transform <code>ToTensor()</code> and followed by <code>Normalize(mean, std)</code>. The value for <code> mean</code> and <code>std</code> are provided for you.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "# transforms.ToTensor()\n",
    "#transforms.Normalize(mean, std)\n",
    "#transforms.Compose([])\n",
    "\n",
    "transform =transforms.Compose([ transforms.ToTensor(), transforms.Normalize(mean, std)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create object for the training data  <code>dataset_train</code> and validation <code>dataset_val</code>. Use the transform object to convert the images to tensors using the transform object:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_train=Dataset(transform=transform,train=True)\n",
    "dataset_val=Dataset(transform=transform,train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We  can find the shape of the image:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 227, 227])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train[0][0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that it's a color image with three channels:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "154587"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size_of_image=3*227*227\n",
    "size_of_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"Question\"> Question <h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Create a custom module for Softmax for two classes,called model. The input size should be the <code>size_of_image</code>, you should record the maximum accuracy achieved on the validation data for the different epochs. For example if the 5 epochs the accuracy was 0.5, 0.2, 0.64,0.77, 0.66 you would select 0.77.</b>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model with the following free parameter values:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Parameter Values</b>\n",
    "   <li>learning rate:0.1 </li>\n",
    "   <li>momentum term:0.1 </li>\n",
    "   <li>batch size training:5</li>\n",
    "   <li>Loss function:Cross Entropy Loss </li>\n",
    "   <li>epochs:5</li>\n",
    "   <li>set: torch.manual_seed(0)</li>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fc4b5cf9e50>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Custom Module:</b>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SoftMax(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(SoftMax, self).__init__()\n",
    "        self.linear = nn.Linear(input_size, output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        z = self.linear(x)\n",
    "        return z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Model Object:</b>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SoftMax(\n",
       "  (linear): Linear(in_features=154587, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dim = 2\n",
    "input_dim = size_of_image\n",
    "model = SoftMax(input_size=input_dim, output_size=output_dim)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "momentum= 0.1\n",
    "batch_size = 1000\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Optimizer:</b>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "optimizer = optim.SGD(params=model.parameters(), lr=learning_rate, momentum=momentum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Criterion:</b>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Data Loader Training and Validation:</b>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=dataset_train, batch_size=batch_size)\n",
    "val_loader = torch.utils.data.DataLoader(dataset=dataset_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Train Model with 5 epochs, should take 35 minutes: </b>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(n_epochs):\n",
    "    max_accuracy = 0.0\n",
    "    loss_list = []\n",
    "    accuracy_list = []\n",
    "    N_test = len(dataset_val)\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(n_epochs):\n",
    "        for x, y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            yhat = model(x.view(-1, size_of_image))\n",
    "            loss = criterion(yhat, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        correct = 0\n",
    "        \n",
    "        #validation\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            for x_test, y_test in val_loader:\n",
    "                yhat = model(x_test.view(-1, size_of_image))\n",
    "                _, yhat = torch.max(yhat.data, 1)\n",
    "                correct += (yhat == y_test).sum().item()\n",
    "        \n",
    "        accuracy = correct / N_test\n",
    "        loss_list.append(loss.item())\n",
    "        accuracy_list.append(accuracy)\n",
    "        \n",
    "        if accuracy > max_accuracy:\n",
    "            max_accuracy = accuracy\n",
    "            \n",
    "    \n",
    "    return max_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
      "Wall time: 7.87 µs\n",
      "Maximum accuracy achieved:  0.7154\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "max_accuracy = train_model(epochs)\n",
    "print('Maximum accuracy achieved: ', max_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>About the Authors:</h2>\n",
    " <a href=\\\"https://www.linkedin.com/in/joseph-s-50398b136/\\\">Joseph Santarcangelo</a> has a PhD in Electrical Engineering, his research focused on using machine learning, signal processing, and computer vision to determine how videos impact human cognition. Joseph has been working for IBM since he completed his PhD.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Change Log\n",
    "\n",
    "|  Date (YYYY-MM-DD) |  Version | Changed By  |  Change Description |\n",
    "|---|---|---|---|\n",
    "| 2020-09-18  | 2.0  | Shubham  |  Migrated Lab to Markdown and added to course repo in GitLab |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright &copy; 2019 <a href=\"cognitiveclass.ai\"> cognitiveclass.ai</a>. This notebook and its source code are released under the terms of the <a href=\"https://bigdatauniversity.com/mit-license/\">MIT License</a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "conda-env-python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "prev_pub_hash": "d76b47f27f3838cee5fcf531fe9ce8abc439f204aaa935161f67b638f12e7c04"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
